{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=\"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\""
      ],
      "metadata": {
        "id": "tcLhUgpmz9Gv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "xWtl9CNU1qZP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Model Response"
      ],
      "metadata": {
        "id": "HL46OGsRz4zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  messages=[\n",
        "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKA7Nksm0N8S",
        "outputId": "9d53cfb6-a579-47f5-a376-46e461ddba38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I help you today?\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generarate Response For Images"
      ],
      "metadata": {
        "id": "PFfBBlCw1-qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "                    }\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4I3kVK02Kbk",
        "outputId": "b3670578-68a3-4e13-e9fa-ac6deac37711"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image shows a scenic landscape featuring a wooden boardwalk or pathway cutting through a lush, green meadow or marsh. The boardwalk stretches into the distance, flanked by tall grasses and some bushes or small trees. The sky above is a vibrant blue with scattered clouds, giving the scene a peaceful and open feeling. The image evokes a sense of tranquility and natural beauty.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#streaming"
      ],
      "metadata": {
        "id": "0HwLISQS2baS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  messages=[\n",
        "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  print(chunk.choices[0].delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwV5xL_p2XPk",
        "outputId": "0e58d3a2-1fcb-4d68-8e9f-e5ed74695801"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None)\n",
            "ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None)\n",
            "ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completions = client.chat.completions.list()\n",
        "first_id = completions[0].id\n",
        "first_completion = client.chat.completions.retrieve(completion_id=first_id)\n",
        "print(first_completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "8av5Tqa52oS1",
        "outputId": "fc184313-698e-48b8-be9b-469531705bcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'SyncCursorPage[ChatCompletion]' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fd054f0cf6dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcompletions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfirst_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_completion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'SyncCursorPage[ChatCompletion]' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completions = client.chat.completions.list()\n",
        "first_id = completions[0].id\n",
        "delete_response = client.chat.completions.delete(completion_id=first_id)\n",
        "print(delete_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "POcqRwvl3La8",
        "outputId": "ba70632a-6e59-4cd4-a6e6-d2cdaecadd3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'SyncCursorPage[ChatCompletion]' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8621685bccc1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcompletions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdelete_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'SyncCursorPage[ChatCompletion]' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function**"
      ],
      "metadata": {
        "id": "yWtO_3-iGiDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "  {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "      \"name\": \"get_current_weather\",\n",
        "      \"description\": \"Get the current weather in a given location\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"location\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "          },\n",
        "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "        },\n",
        "        \"required\": [\"location\"],\n",
        "      },\n",
        "    }\n",
        "  }\n",
        "]\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  messages=messages,\n",
        "  tools=tools,\n",
        "  tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "print(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j27Srr1Z3hlI",
        "outputId": "cbaa710f-4704-4e45-b177-b7a3b25875d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BcT1dHqCJlhAhfH6KuZPBJ7k6O4nc', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_itcFuejlmafi6CdelMQqhBPx', function=Function(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), type='function')]))], created=1748507737, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_ccc6ec921d', usage=CompletionUsage(completion_tokens=17, prompt_tokens=80, total_tokens=97, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ]
    }
  ]
}