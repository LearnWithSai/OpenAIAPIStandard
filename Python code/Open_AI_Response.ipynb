{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2Nx3thl6qAv"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "20zWDGf3GpzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Model Response"
      ],
      "metadata": {
        "id": "Xl2WQdeuGxC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEAHgh6HGy7h",
        "outputId": "78ff42d6-f880-4b7a-c618-1d6f9179a189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_6837f95e943881919c122357c8c473cb0cc4b2bd47a65be9', created_at=1748498782.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_6837f95f569c8191b05c9ab6cea5a9b90cc4b2bd47a65be9', content=[ResponseOutputText(annotations=[], text='Once upon a time, a shy unicorn named Luna discovered a hidden, glowing pond deep in the enchanted forest. When she dipped her horn into the water, magical sparkles twirled around her, granting her the power to make flowers bloom with every step. From that night on, Luna filled the forest with colorful blooms, spreading joy and sweet dreams to all its creatures.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=76, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=94), user=None, store=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generarate Response For Images"
      ],
      "metadata": {
        "id": "PUtN-4OiHBuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                { \"type\": \"input_text\", \"text\": \"what is in this image?\" },\n",
        "                {\n",
        "                    \"type\": \"input_image\",\n",
        "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v1CB6WaHAOd",
        "outputId": "42e53207-a41f-452a-ef74-d586f4bfb8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_682a04d686048191afd618331ea3171a0792120020c6bfc2', created_at=1747584214.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_682a04d897908191b8a9b90460de4f440792120020c6bfc2', content=[ResponseOutputText(annotations=[], text='This image depicts a scenic landscape with a wooden boardwalk pathway leading through a field of tall green grass. There are bushes and trees in the background, and the sky is mostly clear with some scattered clouds. The overall atmosphere is peaceful and natural, likely a park, nature reserve, or wetland area.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1118, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=62, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1180), user=None, store=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#streaming"
      ],
      "metadata": {
        "id": "P5CfdxB7HXRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  instructions=\"You are a helpful assistant.\",\n",
        "  input=\"Hello!\",\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for event in response:\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77XN-FaeHNO7",
        "outputId": "d1494e29-90d3-4c47-fef0-bf99f5d4969e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResponseCreatedEvent(response=Response(id='resp_682a0431027c8191b58365b06e058fbc016627706335fb81', created_at=1747584049.0, error=None, incomplete_details=None, instructions='You are a helpful assistant.', metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.created')\n",
            "ResponseInProgressEvent(response=Response(id='resp_682a0431027c8191b58365b06e058fbc016627706335fb81', created_at=1747584049.0, error=None, incomplete_details=None, instructions='You are a helpful assistant.', metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.in_progress')\n",
            "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', content=[], role='assistant', status='in_progress', type='message'), output_index=0, type='response.output_item.added')\n",
            "ResponseContentPartAddedEvent(content_index=0, item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text'), type='response.content_part.added')\n",
            "ResponseTextDeltaEvent(content_index=0, delta='Hello', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' How', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' can', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' I', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' assist', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta=' today', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDeltaEvent(content_index=0, delta='?', item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, type='response.output_text.delta')\n",
            "ResponseTextDoneEvent(content_index=0, item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, text='Hello! How can I assist you today?', type='response.output_text.done')\n",
            "ResponseContentPartDoneEvent(content_index=0, item_id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', output_index=0, part=ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text'), type='response.content_part.done')\n",
            "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text')], role='assistant', status='completed', type='message'), output_index=0, type='response.output_item.done')\n",
            "ResponseCompletedEvent(response=Response(id='resp_682a0431027c8191b58365b06e058fbc016627706335fb81', created_at=1747584049.0, error=None, incomplete_details=None, instructions='You are a helpful assistant.', metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_682a043143888191a7c06a6589a2dbaa016627706335fb81', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=19, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=10, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=29), user=None, store=True), type='response.completed')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get response"
      ],
      "metadata": {
        "id": "ND4SsYmqHkZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.retrieve(\"resp_682a04d686048191afd618331ea3171a0792120020c6bfc2\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJz4QfiXHejk",
        "outputId": "250d4ddd-5ee6-4499-8e7e-fdfa97891e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_682a04d686048191afd618331ea3171a0792120020c6bfc2', created_at=1747584214.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_682a04d897908191b8a9b90460de4f440792120020c6bfc2', content=[ResponseOutputText(annotations=[], text='This image depicts a scenic landscape with a wooden boardwalk pathway leading through a field of tall green grass. There are bushes and trees in the background, and the sky is mostly clear with some scattered clouds. The overall atmosphere is peaceful and natural, likely a park, nature reserve, or wetland area.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1118, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=62, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1180), user=None, store=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Delete Response"
      ],
      "metadata": {
        "id": "e8nOL2Q2H0PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.delete(\"resp_682a03e719688191bf709692c10e2b830ad85afb6d5ad405\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW6IAJL2H3XK",
        "outputId": "630f0685-7137-4aa5-f964-53955f2be402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get list item"
      ],
      "metadata": {
        "id": "b4vq5wsAIQ7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.input_items.list(\"resp_682a04d686048191afd618331ea3171a0792120020c6bfc2\")\n",
        "print(response.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOQ2PHR_IPXG",
        "outputId": "aadf8d35-12a2-4473-89f2-e4fd889b6dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResponseInputMessageItem(id='msg_682a04d6880c8191b698254f13007c4c0792120020c6bfc2', content=[ResponseInputText(text='what is in this image?', type='input_text'), ResponseInputImage(detail='auto', type='input_image', file_id=None, image_url=None)], role='user', status='completed', type='message')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat response"
      ],
      "metadata": {
        "id": "YceGFlQhIZdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  input=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"input_text\",\n",
        "          \"text\": \"The goal is to provide clear, helpful information and solve common issues users might have with deliveries.\\\\n\\\\n# Steps\\\\n\\\\n- Understand the specific delivery-related issue or question presented by the user.\\\\n- Gather any necessary details from the user, such as order number, tracking information, or expected delivery date.\\\\n- Provide a clear and concise response addressing the user\\\\\\\"s query.\\\\n- Offer additional support or contact information if the issue requires further assistance.\\\\n\\\\n# Output Format\\\\n\\\\nThe response should be in a clear and polite manner, structured in short paragraphs. Use a friendly and professional tone.\\\\n\\\\n# Examples\\\\n\\\\nExample 1:\\\\n- **User Query**: \\\\\\\"I haven\\\\\\\"t received my package yet, and it was supposed to be delivered yesterday.\\\\\\\"\\\\n- **System Message**: \\\\\\\"Thank you for reaching out. I apologize for the delay. Could you please provide your order number so I can check the status of your delivery? In the meantime, you can track your package using our online tracking tool.\\\\\\\"\\\\n\\\\nExample 2:\\\\n- **User Query**: \\\\\\\"I received the wrong item in my order.\\\\\\\"\\\\n- **System Message**: \\\\\\\"I\\\\\\\"m sorry to hear about the inconvenience. Could you please provide your order number and a brief description of the item you received? We\\\\\\\"ll work on resolving this issue quickly for you.\\\\\\\"\\\\n\\\\n# Notes\\\\n\\\\n- Ensure the response is empathetic and seeks to resolve the user\\\\\\\"s concern efficiently.\\\\n- Encourage users to provide specific details needed to address their queries effectively.\\\\n- Include contact information or a method to escalate the issue if necessary.\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"input_text\",\n",
        "          \"text\": \"hi\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"id\": \"msg_682a05a14a40819180bf64fa4c0fe640075b273053e4a52e\",\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"output_text\",\n",
        "          \"text\": \"Hello! How can I help you with your delivery today? If you have a question or need assistance with an order, please let me know the details, and I'll do my best to assist you.\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"input_text\",\n",
        "          \"text\": \"What is the status of Order O143\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  text={\n",
        "    \"format\": {\n",
        "      \"type\": \"text\"\n",
        "    }\n",
        "  },\n",
        "  reasoning={},\n",
        "  tools=[],\n",
        "  temperature=1,\n",
        "  max_output_tokens=2048,\n",
        "  top_p=1,\n",
        "  store=True\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRsoEe0IYhi",
        "outputId": "68a0638d-b91e-477d-e99d-b67d33fa3c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_682a060c8a048191a683db0c063c8700075b273053e4a52e', created_at=1747584524.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_682a060cf17c819194db12a8d3d2f9cd075b273053e4a52e', content=[ResponseOutputText(annotations=[], text='Thank you for your message. Could you please provide a few more details, such as the email address or phone number associated with your order? This will help me look up the status of Order O143 for you.\\n\\nIf you have a tracking number, you can also track your order directly using our online tracking tool. Let me know how you’d like to proceed, and I’m here to help!', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=2048, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=406, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=81, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=487), user=None, store=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tool"
      ],
      "metadata": {
        "id": "CbEGUdlJWvrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = client.vector_stores.create(name=\"learn_with_sai_store\")\n",
        "print(\"Vector Store ID:\", vector_store.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhkUJsp1WsKy",
        "outputId": "bb3d2538-cbf3-4079-9418-96bc261f6ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Store ID: vs_68381cd57e6c8191bba02772dd2dc639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = client.files.create(\n",
        "    file=open(\"brown dragon.pdf\", \"rb\"),\n",
        "    purpose=\"assistants\"\n",
        ")"
      ],
      "metadata": {
        "id": "_s7qDwzvXB20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.vector_stores.file_batches.create(\n",
        "    vector_store_id=vector_store.id,\n",
        "    file_ids=[file.id]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYbNzA_RXQ_W",
        "outputId": "9c248c34-4473-4d5a-c5c4-09ee358008b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreFileBatch(id='vsfb_04993f2c3a834a3492d192f0eb573708', created_at=1748507897, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=1, total=1), object='vector_store.file_batch', status='in_progress', vector_store_id='vs_68381cd57e6c8191bba02772dd2dc639')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "  model=\"gpt-4.1\",\n",
        "  input=\"What are the attributes of an ancient brown dragon?\",\n",
        "  text={\n",
        "    \"format\": {\n",
        "      \"type\": \"text\"\n",
        "    }\n",
        "  },\n",
        "  reasoning={},\n",
        "  tools=[\n",
        "    {\n",
        "      \"type\": \"file_search\",\n",
        "      \"vector_store_ids\": [\n",
        "        \"vs_6837f9bc20288191b6f949ded4089cc7\"\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_output_tokens=2048,\n",
        "  top_p=1,\n",
        "  store=True\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYFC-qUiYFCb",
        "outputId": "fb9d2c90-bec8-4eb1-98b6-515e12c58933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_68381cfb899c81918ee28911700c5c4e00211a8796f2a693', created_at=1748507899.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseFileSearchToolCall(id='fs_68381cfc06f081919e7b27bf5f1fa40c00211a8796f2a693', queries=['attributes of an ancient brown dragon', 'ancient brown dragon statistics', 'ancient brown dragon abilities', 'ancient brown dragon traits', 'ancient brown dragon'], status='completed', type='file_search_call', results=None), ResponseOutputMessage(id='msg_68381cfdc404819190f08a3e7f13b80d00211a8796f2a693', content=[ResponseOutputText(annotations=[], text='The attributes of an ancient brown dragon, based on available content, can include details like its ability scores, resistances, senses, special abilities, breath weapon, legendary actions, and more. However, to give you an accurate breakdown with specifics such as hit points, armor class, ability scores, and unique features, I would need to reference the file directly for the exact numbers and unique abilities. Would you like a summary in the classic stat block format (such as those used in D&D 5th Edition), or are you looking for a more descriptive overview of its characteristics? Let me know your preference!', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_6837f9bc20288191b6f949ded4089cc7'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, background=False, max_output_tokens=2048, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1985, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=171, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2156), user=None, store=True)\n"
          ]
        }
      ]
    }
  ]
}